{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0uS-iAbYmkm"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihpC8VLdD-1y"
      },
      "outputs": [],
      "source": [
        "# dataset path\n",
        "ori_data_dir = \"drive/MyDrive/FYP/data/AFPILD_v1\"\n",
        "\n",
        "# generated feat path\n",
        "afpild_fea_dir = 'drive/MyDrive/FYP/data/audio_feature'\n",
        "\n",
        "# manually create two empty directory at the start for feature saving\n",
        "gcc_cachedir = \"gcc\"\n",
        "spec_cachedir = \"spec\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK2rDvt-EBio"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(os.path.join(afpild_fea_dir, gcc_cachedir)):\n",
        "    os.makedirs(os.path.join(afpild_fea_dir, spec_cachedir))\n",
        "    os.makedirs(os.path.join(afpild_fea_dir, gcc_cachedir))\n",
        "\n",
        "cloth_train_df = pd.DataFrame(columns=[\"fea_spec\", \"fea_gcc\", \"loc_azimuth\", \"loc_x\", \"loc_y\", \"subject_label\"])\n",
        "\n",
        "cloth_test_df = pd.DataFrame(columns=[\"fea_spec\", \"fea_gcc\", \"loc_azimuth\", \"loc_x\", \"loc_y\", \"subject_label\"])\n",
        "\n",
        "shoe_train_df = pd.DataFrame(columns=[\"fea_spec\", \"fea_gcc\", \"loc_azimuth\", \"loc_x\", \"loc_y\", \"subject_label\"])\n",
        "\n",
        "shoe_test_df = pd.DataFrame(columns=[\"fea_spec\", \"fea_gcc\", \"loc_azimuth\", \"loc_x\", \"loc_y\", \"subject_label\"])\n",
        "\n",
        "all_df = pd.DataFrame(columns=[\"fea_spec\", \"fea_gcc\", \"loc_azimuth\", \"loc_x\", \"loc_y\", \"subject_label\"])\n",
        "\n",
        "# sub1, sub2, ...., sub40.\n",
        "ori_sub_dir = sorted(os.listdir(ori_data_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv_cFBm9FcpE",
        "outputId": "d1af8012-5402-47d3-8da2-35301416bff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== subject: 01 ========\n",
            "session: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-dbd086901deb>:116: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  cloth_train_df = pd.concat([cloth_train_df, df_new_row], ignore_index=True)\n",
            "<ipython-input-4-dbd086901deb>:117: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  shoe_train_df = pd.concat([shoe_train_df, df_new_row], ignore_index=True)\n",
            "<ipython-input-4-dbd086901deb>:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  all_df = pd.concat([all_df, df_new_row], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "session: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-dbd086901deb>:121: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  cloth_test_df = pd.concat([cloth_test_df, df_new_row], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "session: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-dbd086901deb>:127: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  shoe_test_df = pd.concat([shoe_test_df, df_new_row], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "session: 4\n",
            "======== subject: 02 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n",
            "======== subject: 03 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n",
            "======== subject: 04 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n",
            "======== subject: 05 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n",
            "======== subject: 06 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n",
            "======== subject: 07 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n",
            "======== subject: 08 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n",
            "======== subject: 09 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n",
            "======== subject: 10 ========\n",
            "session: 1\n",
            "session: 2\n",
            "session: 3\n",
            "session: 4\n"
          ]
        }
      ],
      "source": [
        "sample_num = 1\n",
        "for i in range(10):\n",
        "    sub_dir = os.path.join(ori_data_dir, ori_sub_dir[i])\n",
        "    if os.path.isfile(sub_dir):\n",
        "        continue\n",
        "\n",
        "    audio_dir = sorted(os.listdir(sub_dir))\n",
        "    print(\"======== subject: {} ========\".format(ori_sub_dir[i][1:]))\n",
        "    # iterate over each recorded audio file\n",
        "    for j in range(1, 5):\n",
        "        print(\"session: {}\".format(j))\n",
        "\n",
        "        audio_fil_name = 's' + ori_sub_dir[i][1:] + '_' + str(j) + '_' + 'footstep_audio.wav'\n",
        "        meta_fil_name = 's' + ori_sub_dir[i][1:] + '_' + str(j) + '_' + 'footstep_annotation.csv'\n",
        "\n",
        "        # load the footstep events separation sampling points\n",
        "        meta_fil = pd.read_csv(os.path.join(sub_dir, meta_fil_name))\n",
        "        # load audio\n",
        "        input_audio, sr = librosa.load(os.path.join(sub_dir, audio_fil_name), sr=16000, mono=False)\n",
        "\n",
        "        # select the corresponding FEs separation sampling points\n",
        "        # j starts from 5 to skip the silence beginning\n",
        "        for sample_cnt in range(5, len(meta_fil) - 3):\n",
        "\n",
        "            # for a single footstep event\n",
        "            sample_audio = input_audio[:, meta_fil['sample_loc'][sample_cnt]: meta_fil['sample_loc'][sample_cnt + 1]]\n",
        "\n",
        "            # visualization\n",
        "            # plt.plot(sample_audio[0, :])\n",
        "            # plt.plot(sample_audio[1, :]+0.2)\n",
        "            # plt.plot(sample_audio[2, :] + 0.2*2)\n",
        "            # plt.plot(sample_audio[3, :] + 0.2*3)\n",
        "            # plt.show()\n",
        "\n",
        "            # window length belongs to 20-40 ms, here we choose 20ms, with an overlapping length of 10ms.\n",
        "            # for a single footstep event\n",
        "            win_len = int(0.02 * sr)\n",
        "            step_len = int(0.01 * sr)\n",
        "\n",
        "            # for padding\n",
        "            fixed_sample_len = int(0.64 * sr)\n",
        "            fixed_pad_len = int(fixed_sample_len / step_len)\n",
        "\n",
        "            # mel-spectrogram feature extraction\n",
        "            spectra_fea = []\n",
        "            linear_spectra = []\n",
        "            for ch_cnt in range(4):\n",
        "                spec_ch = librosa.feature.melspectrogram(y=sample_audio[ch_cnt, :], sr=sr, n_fft=2048,\n",
        "                                                         hop_length=step_len, n_mels=64, win_length=win_len,\n",
        "                                                         window='hann', fmin=0, fmax=8000)\n",
        "                spec_ch = np.log(spec_ch)\n",
        "\n",
        "                # z-score normalization\n",
        "                std_val = spec_ch.std()\n",
        "                mean_val = spec_ch.mean()\n",
        "                spec_ch = (spec_ch - mean_val) / std_val + 1e-8\n",
        "\n",
        "                # padding the spectrogram to generate a fixed shape of 64 x 64\n",
        "                f_len = spec_ch.shape[0]\n",
        "                spec_ch_padded = np.zeros((f_len, fixed_pad_len), dtype='float32')\n",
        "                tmp = spec_ch[:, :fixed_pad_len]\n",
        "                spec_ch_padded[:, 0:tmp.shape[1]] = tmp  # ==> for saving\n",
        "\n",
        "                spectra_fea.append(spec_ch_padded)\n",
        "\n",
        "                # linear spectrogram extraction\n",
        "                linear_spectra_ch = librosa.core.stft(np.asfortranarray(sample_audio[ch_cnt, :]), n_fft=2048,\n",
        "                                                      hop_length=step_len, win_length=win_len, window='hann')\n",
        "                linear_spectra.append(linear_spectra_ch)\n",
        "\n",
        "            linear_spectra = np.array(linear_spectra).T  # (time_dim x freq_dim x channel_num)\n",
        "\n",
        "            # gcc-phat feature extraction\n",
        "            gcc_channels = 6\n",
        "            gcc_fea = np.zeros((fixed_pad_len, 64, gcc_channels))  # (time_dim x freq_dim x channel_num)\n",
        "            cnt = 0\n",
        "            for m in range(linear_spectra.shape[-1]):\n",
        "                for n in range(m + 1, linear_spectra.shape[-1]):\n",
        "                    R = np.conj(linear_spectra[:, :, m]) * linear_spectra[:, :, n]\n",
        "                    cc = np.fft.irfft(np.exp(1.j * np.angle(R)))\n",
        "                    cc = np.concatenate((cc[:, -64 // 2:], cc[:, :64 // 2]), axis=-1)\n",
        "\n",
        "                    # z-score normalization\n",
        "                    std_val = cc.std()\n",
        "                    mean_val = cc.mean()\n",
        "                    cc = (cc - mean_val) / std_val + 1e-8\n",
        "\n",
        "                    # padding to the same length of 64 x 64\n",
        "                    tmp = cc[:fixed_pad_len, :]\n",
        "                    gcc_fea[0:tmp.shape[0], :, cnt] = tmp\n",
        "                    cnt += 1\n",
        "\n",
        "            gcc_fea = gcc_fea.transpose((1, 0, 2))  # (freq_dim x time_dim x channel_num)\n",
        "            spectra_fea = np.array(spectra_fea).transpose((1, 2, 0))  # (freq_dim x time_dim x channel_num)\n",
        "\n",
        "            # feature saving  <<<====================\n",
        "            fname_spec = os.path.join(spec_cachedir, f\"afpild_fe1_{audio_fil_name[:5]}_melspec_{sample_num}.npy\")\n",
        "            fname_gcc = os.path.join(gcc_cachedir, f\"afpild_fe1_{audio_fil_name[:5]}_gccphat_{sample_num}.npy\")\n",
        "            sample_num += 1\n",
        "\n",
        "            # saving\n",
        "            # np.save(os.path.join(self.spectrogram_cachedir, item['filename_audio']).replace(\".wav\", \".npy\"), spec)\n",
        "            np.save(os.path.join(afpild_fea_dir, fname_spec), spectra_fea)\n",
        "            np.save(os.path.join(afpild_fea_dir, fname_gcc), gcc_fea)\n",
        "\n",
        "            session = int(audio_fil_name[4])\n",
        "\n",
        "            # convert cartesian to polar\n",
        "            x, y = meta_fil['loc_x'][sample_cnt], meta_fil['loc_y'][sample_cnt]\n",
        "            azimuth = np.arctan2(y, x) * 180 / np.pi  # in degree,  azimuth in [-180, 180]\n",
        "\n",
        "            df_new_row = pd.DataFrame({\"fea_spec\": [fname_spec], \"fea_gcc\": [fname_gcc], \"loc_azimuth\": [azimuth],\n",
        "                                       \"loc_x\": [meta_fil['loc_x'][sample_cnt]], \"loc_y\": [meta_fil['loc_y'][sample_cnt]],\n",
        "                                       \"subject_label\": [f\"S{audio_fil_name[1:3]}\"]})\n",
        "            if session == 1:\n",
        "                cloth_train_df = pd.concat([cloth_train_df, df_new_row], ignore_index=True)\n",
        "                shoe_train_df = pd.concat([shoe_train_df, df_new_row], ignore_index=True)\n",
        "                all_df = pd.concat([all_df, df_new_row], ignore_index=True)\n",
        "\n",
        "            elif session == 2:\n",
        "                cloth_test_df = pd.concat([cloth_test_df, df_new_row], ignore_index=True)\n",
        "                shoe_train_df = pd.concat([shoe_train_df, df_new_row], ignore_index=True)\n",
        "                all_df = pd.concat([all_df, df_new_row], ignore_index=True)\n",
        "\n",
        "            elif session == 3:\n",
        "                cloth_test_df = pd.concat([cloth_test_df, df_new_row], ignore_index=True)\n",
        "                shoe_test_df = pd.concat([shoe_test_df, df_new_row], ignore_index=True)\n",
        "                all_df = pd.concat([all_df, df_new_row], ignore_index=True)\n",
        "\n",
        "            elif session == 4:\n",
        "                cloth_train_df = pd.concat([cloth_train_df, df_new_row], ignore_index=True)\n",
        "                shoe_test_df = pd.concat([shoe_test_df, df_new_row], ignore_index=True)\n",
        "                all_df = pd.concat([all_df, df_new_row], ignore_index=True)\n",
        "\n",
        "            else:\n",
        "                print('========>>>>>>>>>>  ERROR !!!! <<<<<<<<<<============')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTcJzmw0GHcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ad1230-2274-4955-cca4-1603cda378eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished to create the AFPILD_FE1 dataset with a SINGLE footstep event to form ONE sample!\n"
          ]
        }
      ],
      "source": [
        "data_len = len(all_df)\n",
        "samp_idx = np.random.permutation(np.arange(data_len))\n",
        "train_len = int(data_len * 0.8)\n",
        "\n",
        "train_pd_rd = all_df.iloc[samp_idx[:train_len]]\n",
        "train_pd_rd.reset_index(drop=True, inplace=True)\n",
        "\n",
        "test_pd_rd = all_df.iloc[samp_idx[train_len:]]\n",
        "test_pd_rd.reset_index(drop=True, inplace=True)\n",
        "\n",
        "train_pd_rd.to_csv(os.path.join(afpild_fea_dir, \"AFPILD_FE1_rd_train.csv\"))\n",
        "test_pd_rd.to_csv(os.path.join(afpild_fea_dir, \"AFPILD_FE1_rd_test.csv\"))\n",
        "# all_df.to_csv(os.path.join(afpild_fea_dir, \"AFPILD_FE1_all.csv\"))\n",
        "\n",
        "cloth_train_df.to_csv(os.path.join(afpild_fea_dir, 'AFPILD_FE1_cloth_train.csv'))\n",
        "cloth_test_df.to_csv(os.path.join(afpild_fea_dir, 'AFPILD_FE1_cloth_test.csv'))\n",
        "\n",
        "shoe_train_df.to_csv(os.path.join(afpild_fea_dir, 'AFPILD_FE1_shoe_train.csv'))\n",
        "shoe_test_df.to_csv(os.path.join(afpild_fea_dir, 'AFPILD_FE1_shoe_test.csv'))\n",
        "\n",
        "print(\"Finished to create the AFPILD_FE1 dataset with a SINGLE footstep event to form ONE sample!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvmHM3pwhPYB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}