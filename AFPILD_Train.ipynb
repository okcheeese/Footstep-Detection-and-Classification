{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beMT6URQKY_X"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.2)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Shreesh/University/FYP/AFPILD-CRNN/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a8IaIYqE9uYd"
      },
      "outputs": [],
      "source": [
        "#  for reproducability\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U1R-mgb090Ih"
      },
      "outputs": [],
      "source": [
        "def load_data_from_csv(csv_path, feature_dir):\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    display(df)\n",
        "\n",
        "    gcc_features = []\n",
        "    spec_features = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # loading gcc features\n",
        "        gcc_path = os.path.join(feature_dir, row['fea_gcc'])\n",
        "        print(gcc_path)\n",
        "        gcc_feature = np.load(gcc_path)\n",
        "        gcc_features.append(gcc_feature)\n",
        "\n",
        "        # loading mel spec features\n",
        "        spec_path = os.path.join(feature_dir, row['fea_spec'])\n",
        "        print(spec_path)\n",
        "        spec_feature = np.load(spec_path)\n",
        "        spec_features.append(spec_feature)\n",
        "\n",
        "        # adding a label\n",
        "        labels.append(row['subject_label'])\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    gcc_features = np.array(gcc_features)\n",
        "    spec_features = np.array(spec_features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return gcc_features, spec_features, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Iy2eN99y94Ye"
      },
      "outputs": [],
      "source": [
        "\n",
        "def encode_labels(labels):\n",
        "    # encoding labels\n",
        "    unique_labels = np.unique(labels)\n",
        "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    encoded_labels = np.array([label_to_index[label] for label in labels])\n",
        "    return encoded_labels, label_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b-ZvID-u-I8t"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model(input_shape_gcc, input_shape_spec, hidden_units, output_units, dropout_rate=0.2):\n",
        "    # input branch for gcc features\n",
        "    gcc_input = Input(shape=input_shape_gcc)\n",
        "    gcc_lstm = LSTM(hidden_units, return_sequences=True)(gcc_input)\n",
        "    gcc_dropout = Dropout(dropout_rate)(gcc_lstm)\n",
        "\n",
        "    # input branch for mel spec features\n",
        "    spec_input = Input(shape=input_shape_spec)\n",
        "    spec_lstm = LSTM(hidden_units, return_sequences=True)(spec_input)\n",
        "    spec_dropout = Dropout(dropout_rate)(spec_lstm)\n",
        "\n",
        "    # concat the two branches\n",
        "    merged = Concatenate()([gcc_dropout, spec_dropout])\n",
        "\n",
        "    # second lstm later\n",
        "    lstm_2 = LSTM(hidden_units // 2, return_sequences=False)(merged)\n",
        "    lstm_dropout = Dropout(dropout_rate)(lstm_2)\n",
        "\n",
        "    # o/p later\n",
        "    output = Dense(output_units, activation='softmax')(lstm_dropout)\n",
        "\n",
        "    # create the model\n",
        "    model = Model(inputs=[gcc_input, spec_input], outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FEPqZKJV-BFz"
      },
      "outputs": [],
      "source": [
        "def main(feature_dir, csv_train_path, csv_test_path, batch_size=10, epochs=1, lr=0.001):\n",
        "    # logging\n",
        "    log_dir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # loading training data\n",
        "    train_gcc, train_spec, train_labels = load_data_from_csv(csv_train_path, feature_dir)\n",
        "    train_labels, label_to_index = encode_labels(train_labels)\n",
        "\n",
        "    # loading test data\n",
        "    test_gcc, test_spec, test_labels = load_data_from_csv(csv_test_path, feature_dir)\n",
        "    test_labels = np.array([label_to_index[label] for label in test_labels])\n",
        "\n",
        "    # split training data and validation\n",
        "    X_train_gcc, X_val_gcc, X_train_spec, X_val_spec, y_train, y_val = train_test_split(\n",
        "        train_gcc, train_spec, train_labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # building lstm model\n",
        "    input_shape_gcc = (X_train_gcc.shape[1], X_train_gcc.shape[2])  # (timesteps, features) for GCC\n",
        "    input_shape_spec = (X_train_spec.shape[1], X_train_spec.shape[2])  # (timesteps, features) for Mel-spectrogram\n",
        "    model = build_lstm_model(\n",
        "        input_shape_gcc=input_shape_gcc,\n",
        "        input_shape_spec=input_shape_spec,\n",
        "        hidden_units=128,\n",
        "        output_units=len(label_to_index),  # Number of unique subjects\n",
        "        dropout_rate=0.2\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=lr),\n",
        "        loss='sparse_categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' for integer labels\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=os.path.join(log_dir, 'best_model.h5'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max'\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        [X_train_gcc, X_train_spec], y_train,\n",
        "        validation_data=([X_val_gcc, X_val_spec], y_val),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=[tensorboard_callback, checkpoint_callback]\n",
        "    )\n",
        "\n",
        "    # testing\n",
        "    test_loss, test_accuracy = model.evaluate([test_gcc, test_spec], test_labels, verbose=2)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5bY7gJ0i97sr",
        "outputId": "f1cf956c-babf-454b-9497-35ed28ae5395"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Define paths\n",
        "    feature_dir = \"/content/drive/MyDrive/FYP/data/audio_feature\"  # Directory containing the .npy feature files\n",
        "    csv_train_path = \"/content/drive/MyDrive/FYP/data/audio_feature/AFPILD_FE1_rd_train.csv\"  # Path to the training CSV file\n",
        "    csv_test_path = \"/content/drive/MyDrive/FYP/data/audio_feature/AFPILD_FE1_rd_test.csv\"  # Path to the test CSV file\n",
        "\n",
        "    # Run the main function\n",
        "    main(feature_dir, csv_train_path, csv_test_path, batch_size=10, epochs=1, lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lapCRMUA-MN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
